{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import os\n",
    "\n",
    "url = \"https://search.sciencemag.org/?order=oldest&limit=textFields&pageSize=500&startDate=2008-01-01&endDate=2008-12-31&articleTypes=Research%20and%20reviews&source=sciencemag%7CScience\"\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "driver.get(url)\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = []\n",
    "links = []\n",
    "\n",
    "for a in soup.select('h2.media__headline a[href]'):\n",
    "    title.append(a.text)\n",
    "    links.append(a['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pandas.DataFrame({'name':title,'links':links})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('2008-science.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2009"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import os\n",
    "\n",
    "url = \"https://search.sciencemag.org/?order=oldest&limit=textFields&pageSize=500&startDate=2009-01-01&endDate=2009-12-31&articleTypes=Research%20and%20reviews&source=sciencemag%7CScience\"\n",
    "\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "driver.get(url)\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = []\n",
    "links = []\n",
    "\n",
    "for a in soup.select('h2.media__headline a[href]'):\n",
    "    title.append(a.text)\n",
    "    links.append(a['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pandas.DataFrame({'name':title,'links':links})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('2009-science.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get article type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_excel('2008-science.xlsx')\n",
    "\n",
    "article_type1 = []\n",
    "\n",
    "for links in df1['links']:\n",
    "    url = links\n",
    "\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    article_type1.append(soup.find_all('div', {'class': 'overline'})[0].text)\n",
    "\n",
    "df1['type'] = article_type1\n",
    "df1.drop(df1.columns[0], axis=1, inplace=True)\n",
    "df1.to_csv('2008-science-with-type.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_excel('2009-science.xlsx')\n",
    "\n",
    "article_type2 = []\n",
    "\n",
    "for links in df2['links']:\n",
    "    url = links\n",
    "\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    article_type1.append(soup.find_all('div', {'class': 'overline'})[0].text)\n",
    "\n",
    "df2['type'] = article_type2\n",
    "df2.drop(df2.columns[0], axis=1, inplace=True)\n",
    "df2.to_csv('2008-science-with-type.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random sample generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('2008-science-with-type.csv')\n",
    "df2 = pd.read_csv('2009-science-with-type.csv')\n",
    "\n",
    "df1['Year'] = ['2008'] * len(df1)\n",
    "df2['Year'] = ['2009'] * len(df2)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df = df.append(df1, ignore_index=True)\n",
    "df = df.append(df2, ignore_index=True)\n",
    "\n",
    "df.loc[df['type'] == 'Brevia', 'Article Type'] = 'Research Article'\n",
    "df.loc[df['type'] == 'BreviaGenetics', 'Article Type'] = 'Research Article'\n",
    "\n",
    "df.loc[df['type'] == 'Research Articles', 'Article Type'] = 'Research Article'\n",
    "df.loc[df['type'] == 'Research Article', 'Article Type'] = 'Research Article'\n",
    "df.loc[df['type'] == 'Research Articles', 'Article Type'] = 'Research Article'\n",
    "\n",
    "df.loc[df['type'] == 'Special Reviews', 'Article Type'] = 'Review'\n",
    "df.loc[df['type'] == 'Special Reports', 'Article Type'] = 'Research Article'\n",
    "df.loc[df['type'] == 'Review', 'Article Type'] = 'Review'\n",
    "\n",
    "df.drop(df.columns[0], axis=1, inplace=True)\n",
    "\n",
    "shuffled_df = df.sample(frac=1, random_state=2021).reset_index(drop=True)\n",
    "df_2008 = shuffled_df[shuffled_df['Year'] == '2008'].sample(13,\n",
    "                                                            random_state=2021)\n",
    "df_2009 = shuffled_df[shuffled_df['Year'] == '2009'].sample(13,\n",
    "                                                            random_state=2021)\n",
    "\n",
    "df_2008.to_csv('2008-science-rand-sample.csv')\n",
    "df_2009.to_csv('2009-science-rand-sample.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
